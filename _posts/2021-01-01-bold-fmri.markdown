---
layout: post
title:  "BOLD fMRI"
date:   2020-01-02 11:11:03 -0400
categories: medical imaging
---
## Motivation
Blood oxygen level dependent functional magnetic resonance imaging (BOLD fMRI) is the most common method for measuring human brain activity non-invasively in-vivo. BOLD fMRI images are 4-dimensional, consisting of a time series of 3d volume, acquired in quick succession (every 1 or 2 seconds) typically over a period of 8 --- 15 minutes.

Here, we will work with "[*multisubject, multimodal face processing*](https://openneuro.org/datasets/ds000117/versions/1.0.4)" dataset (subject-01) available at *openneuro.org*. This dataset involves presentation of images of faces to the subject while acquiring BOLD fMRI images of the subject's brain activity. Here, we will preprocess these scans and then, localize the brain area that processes faces.

## Preparation
We need both *afni* and *FSL* software packages. Install VirtualBox and then download [*Neurodebian*](https://neuro.debian.net/) and open it in VirtualBox by selecting `File->Import Appliance`. *Neurodebian* is a Linux distribution of the Debian flavor.

Once installed, we will be able to run the preprocessing pipeline on the data from *openneuro*.

## Basic pre-preprocessing
Basic preprocessing includes motion correction, bandpass filtering, spatial smoothing. Run pre-processing pipeline [*pipeline.sh*](https://github.com/zyz9066/Image-Analysis/blob/master/BOLD%20fMRI/pipeline.sh) from the command terminal. The pipeline will take roughly 5 --- 10 minutes to run, depending on hardware setup. The processing pipeline will produce a final output called *clean_bold.nii.gz*, we will use this image for further work.

![](https://zyz9066.github.io/images/516/3/ScreenShot.png)

Above is a screenshot of the directory after running *pipeline.sh*.

## Localize task activation
Briefly, task-based analysis procedure is as follows:
1. Clean the BOLD images (using *pipeline.sh*);
2. Load the *clean_bold.nii.gz* image output by *pipeline.sh* and *events.tsv* which corresponding to each BOLD image;
3. Using the timing form *events.tsv*, create an "ideal time series" that represents how the brain should react to the stimulus (face=1, no face=0);

```python
import nibabel as nib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

clean_bold = nib.load('/clean_bold.nii.gz')
events = pd.read_csv('/events.tsv', delimiter='\t')
tr = clean_bold.header.get_zooms()[3]

ts = np.zeros(int(tr * clean_bold.shape[3]))

ts[np.round(events[~events['stim_type'].isna()]['onset'].values).astype('uint16')] = 1

plt.plot(ts); plt.xlabel('time(seconds)');
```

![](https://zyz9066.github.io/images/516/3/ts.png)

4. Convolve the "ideal time series" the [hemodynamic response function (HRF)](https://github.com/zyz9066/Image-Analysis/blob/master/BOLD%20fMRI/hrf.csv), we can use *pandas* load *hrf.csv* `hrf = pd.read_csv('hrf.csv', header=None)`;
```python
hrf = pd.read_csv('hrf.csv', header=None).values.ravel()
plt.plot(hrf); plt.xlabel('time(seconds)');
```

![](https://zyz9066.github.io/images/516/3/hrf.png)

```python
import scipy.signal as signal

conved = signal.convolve(ts, hrf, mode='full')[:ts.shape[0]]

plt.plot(ts); plt.plot(conved*3); plt.xlabel('time(seconds)');
```

![](https://zyz9066.github.io/images/516/3/cts.png)

5. Correlate the convolved ideal with the BOLD signal in each voxel;

```python
conved = conved[::int(tr)]
img = clean_bold.get_fdata()

meansub_img = img - np.expand_dims(img.mean(-1), 3)
meansub_conved = conved - conved.mean()

corrs = (meansub_img * meansub_conved).sum(-1) / \
    np.sqrt((meansub_img * meansub_img).sum(-1)) / np.sqrt(np.dot(meansub_conved, meansub_conved))

corrs[np.isnan(corrs)] = 0

corrs_nifti = nib.Nifti1Image(corrs, clean_bold.affine)
nib.save(corrs_nifti, 'corrs.nii.gz')
```

```python
from sklearn.metrics import mutual_info_score

def MI(a):
    c_xy = np.histogram2d(a, conved)[0]
    return mutual_info_score(None, None, contingency=c_xy)

mi = np.apply_along_axis(MI, 3, img)

mi_nifti = nib.Nifti1Image(mi, clean_bold.affine)
nib.save(mi_nifti, path+str(i)+'/mi.nii.gz')
```

6. Visualize the correlation map to see where in the brain the activation is strongest.

```python
plt.imshow(np.rot90(corrs.max(2))); plt.colorbar();
plt.imshow(np.rot90(corrs.max(2)), vmin=-0.25, vmax=0.25); plt.colorbar();
```

![](https://zyz9066.github.io/images/516/3/corr.png)

![](https://zyz9066.github.io/images/516/3/corrv.png)

```python
plt.imshow(np.rot90(mi.max(2))); plt.colorbar();
plt.imshow(np.rot90(mi.max(2)), vmin=-0.25, vmax=0.25); plt.colorbar();
```

![](https://zyz9066.github.io/images/516/3/mi.png)

![](https://zyz9066.github.io/images/516/3/miv.png)
